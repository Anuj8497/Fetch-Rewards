{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the brands json file\n",
    "with open(r'C:\\Users\\anuj8\\fetch-data\\brands.json') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the json file into dataframe\n",
    "brands = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While exploring the data, we see there are key value pairs in various columns. We will be required to clean the data so that\n",
    "# each column has a particular value\n",
    "brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to perform data cleaning and making the data structured\n",
    "def CleanBrands(brands):\n",
    "    brands_clean = brands.copy()\n",
    "    for i in range(len(brands_clean)):\n",
    "        brands_clean['_id'].iloc[i] = list(brands_clean['_id'].iloc[i].values())[0]\n",
    "        try:\n",
    "            brands_clean['cpg'].iloc[i] = list(list(brands_clean['cpg'].iloc[i].values())[0].values())[0]\n",
    "        except:\n",
    "            brands_clean['cpg'].iloc[i] = list(list(brands_clean['cpg'].iloc[i].values())[1].values())[0]\n",
    "    #mysql database doesn't take NaN hence replaced with keyword None\n",
    "    brands_clean.replace({np.NaN : None},inplace =True)\n",
    "    return brands_clean       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_clean = CleanBrands(brands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the users json file\n",
    "with open(r'C:\\Users\\anuj8\\fetch-data\\users.json') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the json file into dataframe\n",
    "users = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While exploring the data, we see there are key value pairs in various columns. We will be required to clean the data so that\n",
    "# each column has a particular value. And also converting the createdDate column into DateTime format\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to perform data cleaning and making the data structured and in the correct format.\n",
    "def CleanUsers(users):\n",
    "    clean_users = users.copy()\n",
    "    for i in range(len(clean_users)):\n",
    "        clean_users['_id'].iloc[i] = list(clean_users['_id'].iloc[i].values())[0]\n",
    "        try:    \n",
    "            clean_users['createdDate'].iloc[i] = pd.to_datetime(list(clean_users['createdDate'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            clean_users['lastLogin'].iloc[i] = pd.to_datetime(list(clean_users['lastLogin'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "        clean_users.replace({np.NaN : None},inplace =True)\n",
    "    return clean_users       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_users = CleanUsers(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the receipts json file\n",
    "with open(r'C:\\Users\\anuj8\\fetch-data\\receipts.json') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While exploring the data, we see there are key value pairs in various columns. We will be required to clean the data so that\n",
    "# each column has a particular value. And also converting all the date columns into DateTime format\n",
    "receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a function to perform data cleaning and making the data structured and in the correct format.\n",
    "def CleanReceipts(receipts):\n",
    "    clean_receipts = receipts.copy()\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:\n",
    "            clean_receipts['_id'].iloc[i] = list(clean_receipts['_id'].iloc[i].values())[0]\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:    \n",
    "            clean_receipts['createDate'].iloc[i] = pd.to_datetime(list(clean_receipts['createDate'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:    \n",
    "            clean_receipts['dateScanned'].iloc[i] = pd.to_datetime(list(clean_receipts['dateScanned'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:    \n",
    "            clean_receipts['finishedDate'].iloc[i] = pd.to_datetime(list(clean_receipts['finishedDate'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:\n",
    "            clean_receipts['modifyDate'].iloc[i] = pd.to_datetime(list(clean_receipts['modifyDate'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:\n",
    "            clean_receipts['pointsAwardedDate'].iloc[i] = pd.to_datetime(list(clean_receipts['pointsAwardedDate'].iloc[i].values())[0],unit = 'ms')\n",
    "        except:\n",
    "            continue\n",
    "    for i in range(len(clean_receipts)):\n",
    "        try:    \n",
    "            clean_receipts['purchaseDate'].iloc[i] = pd.to_datetime(list(clean_receipts['purchaseDate'].iloc[i].values())[0],unit = 'ms')  \n",
    "        except:\n",
    "            continue\n",
    "    # We have a nested key value pairs inside rewardsReceiptItemList column. The following lines of code makes the data structured\n",
    "    # also takes in keys from these nested key value pairs and creates respective columns out of it.\n",
    "    sub = clean_receipts[['rewardsReceiptItemList','userId','_id']]\n",
    "    \n",
    "    new_frame = []\n",
    "    no_rewards = []\n",
    "    for i in range(len(sub)):\n",
    "        try:\n",
    "            for items in sub['rewardsReceiptItemList'].iloc[i]:\n",
    "                items['userId'] = sub['userId'].iloc[i]\n",
    "                items['_id'] = sub['_id'].iloc[i]\n",
    "                new_frame.append(items)\n",
    "        except:\n",
    "                x = {'userId': sub['userId'].iloc[i],'_id':sub['_id'].iloc[i]}  \n",
    "                no_rewards.append(x)\n",
    "    x = pd.DataFrame(new_frame)\n",
    "    y = pd.DataFrame(no_rewards)\n",
    "    new = pd.concat([x,y],axis = 0)\n",
    "    final = pd.merge(clean_receipts,new, how = 'inner',on = ['_id','userId'])\n",
    "    final_receipts = final.drop('rewardsReceiptItemList',axis = 1)\n",
    "    final_receipts.replace({np.NaN : None},inplace =True)\n",
    "    \n",
    "    return final_receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_receipts = CleanReceipts(receipts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_receipts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have our data structured. We will import it into database. i'll import it into MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing a connection with the MySQL database\n",
    "# Note: Database raw_fetch was already created using the MySQL workbench\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('mysql+mysqldb://root:1234@localhost:3306/raw_fetch', echo = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before executing below cells execute first create the database in the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing dataframes as SQL tables in the database\n",
    "clean_users.to_sql(name = 'users', con = engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing dataframes as SQL tables in the database\n",
    "clean_receipts.to_sql(name = 'receipts', con = engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing dataframes as SQL tables in the database\n",
    "brands_clean.to_sql(name = 'brands', con = engine, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
